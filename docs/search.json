[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "temp",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "PM566_Midterm.html",
    "href": "PM566_Midterm.html",
    "title": "Midterm Project",
    "section": "",
    "text": "Catapult devices are GPS trackers worn by athletes. Wearable-based tracking technologies are used throughout sport to support performance monitoring. In addition to GPS capability, these devices contain inertial sensors comprising of an accelerometer (to measure acceleration forces), a gyroscope (to measure rotation), and a magnetometer (to measure body orientation). Inertial sensors collect data in three axes, or directions, allowing sensitive ‘maps’ of athlete movements and actions to be created. For Catapult’s website, they claim: “The combination of the wearable tracking device and the inertial sensors creates a powerful athlete monitoring tool that ensures that key performance decisions are always supported with objective data.” The sports performance department at LA Galaxy uses Catapult data to make decisions about performance readiness, rehabilitation, and training prescription.\nThis data is Catapult data collected over the course of the U17 2022-2023 season. I will specifically be look at U17 game data for that season. As a student in the USC Sports Science program and an intern at the LA Galaxy Sports Performance Department, I’ve had the opportunity to assist with collecting this data since January 2023. This data is typically visualized using either Catapult’s Cloud where they offer many widgets to visualize data, or an internal athlete management system. LA Galaxy has been developing an athlete management system using Microsoft Azure. They export the data from Catapult and import it to Azure and have customized many different dashboards to visualize data. For this project, I decided to export CSVs directly from Catapult and try to wrangle the data myself.\nCatapult data is collected at every training session and game. The players wear the devices on vests produced by Catapults and the GPS units are stored in a secure pouch on the back of the vest. During training or games, a member of the sport performance department will have an iPad which has the Vector app created by Catapult. The Vector app allows the user to input information about the training session or game, and it produces a live view of the Catapult data per player. The user can start and stop “Periods” based on training drills and which players are participating. After training, all the units are collected, put into a dock, and uploaded to a computer. This data is then available in the Cloud and can be exported to the athlete management system for further visualization.\nWhen thinking about this data, my research question became: does fatigue affect player’s physical performance in soccer matches? More specifically, are players less physically productive when they are tired? To answer this question, I looked at the data at a few levels. To start off, I look at the difference in player’s maximum velocities in the first half of games vs the second half. Then, I look at a string of five games in seven games that the team played in difficult conditions in the MLS Next Tournament, which was played in June of this year.\n\n\n\n\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n# This is where I stored the downloaded CSVs from Catapult\nsetwd(\"/Users/sylwialipior/Downloads/pm566-01-lab/U17 2022-2023 Data\")\n\n# Get a list of all CSV files containing \"_GD_\"\nfilenames &lt;- list.files(pattern = \"_GD_.*\\\\.csv$\")\n\n\n\n\nWhen you export bulk CSVs from Catapult, you get observations for every player involved in the session for 1699 variables. A lot of that data is a little redundant, but I wrote a function to subset the data with only around 34 variables of interest to make it more manageable. The CSVs don’t have the activity name easily accessible, so I wrote a function to extract the names from the names of the CSV files. I then wrote a for loop to read in all the data (~57 CSVs which corresponds to data from 57 games), making a new variable for the date of the session, and a new variable for the activity name. Finally, I de-identified the data since the data contains player names.\n\nsetwd(\"/Users/sylwialipior/Downloads/pm566-01-lab/U17 2022-2023 Data\")\n\n# List of desired variables\ndesired_variables &lt;- c(\n    \"Player.Name\", \"Period.Name\", \"Period.Number\", \"Position.Name\", \n    \"Total.Duration\", \"Total.Distance\", \"Total.Player.Load\", \n    \"Player.Load.Per.Minute\", \"Player.Load.Per.Metre\", \"Meterage.Per.Minute\", \n    \"Maximum.Velocity\", \"High.Speed.Distance.12mph.14mph\", \n    \"Very.High.Speed.Distance.14mph.17mph\", \"Sprinting.Distance.17.19mph\", \n    \"Supra.Max.Velocity..19mph\", \"Number.of.Sprints\", \n    \"Velocity.Band.7.Average.Effort.Count\", \"Velocity.Band.8.Average.Effort.Count\", \n    \"Max.Vel....Max.\", \"Profile.Max.Velocity\", \"Explosive.Efforts\", \n    \"HSD.min\", \"Total.High.Intensity.Bouts..THIB.\", \"Maximal.High.Intensity.Bouts..MHIB.\", \n    \"Accels..2.5...3.m.s.s.\", \"Accels..3...3.5.m.s.s.\", \"Accels....3.5.m.s.s.\", \n    \"Decels...2.5....3.m.s.s\", \"Decels...3....3.5.m.s.s.\", \"Decels.....3.5.m.s.s.\", \n    \"Acceleration.Density\", \"Acceleration.Density.Index\"\n)\n\n#Function to read only columns of interest\nread_selected_columns &lt;- function(filename) {\n    # Read the entire CSV\n    data &lt;- read.csv(filename, skip = 9, header = TRUE, sep = \",\")\n    \n    # Subset the data to keep only the desired columns\n    data &lt;- data[, desired_variables, drop = FALSE]\n    \n    return(data)\n}\n\n# Function to extract and format the activity name from filename\nextract_activity_name &lt;- function(filename) {\n    # Extract the part of the filename after U17 and before the file extension\n    name_part &lt;- sub(\".*U17_([^\\\\.]+)\\\\.csv$\", \"\\\\1\", filename)\n    \n    # Replace underscores with spaces\n    activity_name &lt;- gsub(\"_\", \" \", name_part)\n    \n    # Prepend \"U17 \" to the modified name\n    paste(\"U17\", activity_name)\n}\n\n# Initialize an empty list to hold individual data frames\ndata_frames &lt;- list()\n\n# Loop through each file, read it, and add to the list\nfor (filename in filenames) {\n    df &lt;- read_selected_columns(filename)\n    \n    #Extract the activity name from the filename\n    activity_name &lt;- extract_activity_name(filename)\n    \n    # Extract date information from the filename\n    date_string &lt;- substr(filename, 1, 10) # Assuming the date is always the first 10             characters\n    date_obj &lt;- as.Date(date_string, format = \"%Y_%m_%d\")\n    \n    # Add new columns for date and activity name\n    df$Date &lt;- date_obj\n    df$Activity_Name &lt;- activity_name\n    \n    data_frames[[filename]] &lt;- df  # using filename as list name just for clarity, can use any     naming convention\n}\n\n# Combine all data frames into one master data frame\nmaster_df &lt;- bind_rows(data_frames)\n\n## De-identifying the data\n# Generate a unique identifier for each player name\nunique_players &lt;- unique(master_df$Player.Name)\nname_mapping &lt;- data.frame(\n    Original_Name = unique_players,\n    Identifier = paste0(\"Player_\", seq_along(unique_players))\n)\n\n# Replace the actual player names with the generated identifiers\nmaster_df$Player.Name &lt;- name_mapping$Identifier[match(master_df$Player.Name, name_mapping$Original_Name)]\n\n\n\n\n\nNext, I wanted to make sure the data looks how I would expect it to. Since the session names are inputted by staff, there is some room for error, and I wanted to make sure I have only game data here. To accomplish this, I decided to plot maximum velocity for each activity by month.\n\n# Extract month and year from the Date column to create a new 'Month' column\nmaster_df$Month &lt;- format(master_df$Date, \"%m\")\n\n# List of unique months\nunique_months &lt;- unique(master_df$Month)\n\n# # Loop through each month, create a plot, and then add a page break\n# for (month in unique_months) {\n#   sub_df &lt;- master_df[master_df$Month == month, ]\n#   \n#   print(\n#     ggplot(sub_df, aes(x = Activity_Name, y = Maximum.Velocity, fill = Activity_Name)) +\n#       geom_boxplot() +\n#       theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n#       labs(title = paste(\"Max Speeds of Players for Month\", month),\n#            x = \"Activity\",\n#            y = \"Max Speed (mph)\") +  \n#       theme(legend.position = \"none\")\n#   )\n#   \n#   # Add a page break after each plot\n#   cat(\"\\\\newpage\")\n# }\n\n\n# Filter out the unwanted activities\nmaster_df &lt;- master_df %&gt;%\n  filter(!(Activity_Name %in% c(\"U17 GD vs RSL\", \"U17 GD Pre Season Day 2\")))\n\nFrom looking at the initial box plots, I figured out that there is some data in the set that doesn’t belong. Specifically, “U17 GD vs RSL” seems to have an issue with the GPS data since the maximum velocities are so low, so I decided to remove that data. In addition, the maximum velocities for “U17 GD Pre Season Day 2” are much lower than expected. Once I looked at the period names, I realized that this is data from a training session that was mislabeled as a game, so I removed it from the data set. I included the code to produce these box plots, but decided not to render here, because I did not use them for further analysis.\n\n\n\nFor some more initial visualization, I decided to look at the relationship between “Player Load”, which is defined by Catapult as “the sum of the accelerations across all axes of the internal tri-axial accelerometer during movement”, and a few other physical metrics. Specifically, I looked at scatterplot of Player Load vs Total Distance Covered, Total Number of Sprints, Explosive Efforts, and Total High Intensity Bouts.\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(knitr)\n\n# Filter data for when Period.Name is \"Session\" and for games in September\nfiltered_df &lt;- master_df %&gt;% \n               filter(Period.Name == \"Session\")\n\nggplot(filtered_df, aes(x = Total.Player.Load, y = Total.Distance, color = Player.Name)) +\n    geom_point() +\n    labs(title = \"Scatterplot of Player Load vs. Distance Covered\", x = \"Total Player Load\",\n         y = \"Total Distance\") +\n    theme(legend.position = \"none\")\n\n\n\nggplot(filtered_df, aes(x = Total.Player.Load, y = Number.of.Sprints, color = Player.Name)) +\n    geom_point() +\n    labs(title = \"Scatterplot of Player Load vs. Total Number of Sprints\", x = \"Total Player Load\",\n         y = \"Total Number of Sprints\") +\n    theme(legend.position = \"none\")\n\n\n\nggplot(filtered_df, aes(x = Total.Player.Load, y = Explosive.Efforts, color = Player.Name)) +\n    geom_point() +\n    labs(title = \"Scatterplot of Player Load vs. Explosive Efforts\", x = \"Total Player Load\",\n         y = \"Explosive Efforts\") +\n    theme(legend.position = \"none\")\n\n\n\nggplot(filtered_df, aes(x = Total.Player.Load, y = Total.High.Intensity.Bouts..THIB., color = Player.Name)) +\n    geom_point() +\n    labs(title = \"Scatterplot of Player Load vs. Total High Intensity Bouts\", x = \"Total Player Load\",\n         y = \"Total High Intensity Bouts\") +\n    theme(legend.position = \"none\")\n\n\n\n\nAfter looking at the plots, as expected there is a strong positive correlation between Player Load and all the other physical metrics. In other words, as a player covers more distance, or performs more sprints, explosive efforts, or high intensity bouts, their player load is expected to be higher.\n\n\n\nI thought it would be interesting to analyze maximum velocity from the dataset. Unfortunately, the data is a little difficult, because there are various Period Names that could signify either First Half or Second Half game data. Therefore, I used mutate to add a variable called “Period.Name.Halves” to denote which observations are from the first half vs the second half. I also removed Goal Keeper data, since their data looks very different from field players due to the nature of their position. I added a threshold of 10mph for speed, to make sure that I am actually using game data, and not some other potentially mislabeled data. I then visualized the maximum velocity data in a few different ways.\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n\n# Mutate new variable based on criteria\nmaster_df &lt;- master_df %&gt;%\n  mutate(Period.Name.Halves = case_when(\n    Period.Name %in% c(\"1st Half\", \"0- 10 min\", \"10-45min\", \"0-15mins\", \"15-30mins\", \"30-45mins\") ~ \"First Half\",\n    Period.Name %in% c(\"2nd Half\", \"45-60mins\", \"60-70mins\", \"70-90mins\", \"45-70mins\", \"70-75mins\", \n                       \"75-90mins\", \"66-80min\", \"80-85min\", \"85-90min\", \"45-50mins\", \"50-65mins\", \"60-75mins\",\n                       \"45-75mins\", \"75-83min\", \"83-90min\", \"45-55mins\", \"55-60mins\", \"60-72mins\", \"72-90mins\",\n                       \"56-60mins\", \"55-70mins\", \"70-77mins\", \"77-90mins\", \"70-74mins\", \"74-83mins\", \"83-90mins\",\n                       \"60-69mins\", \"69-77mins\", \"77-83mins\", \"75-78mins\", \"78-85mins\", \"85-90mins\", \"75-80mins\",\n                       \"80-90mins\", \"45-58mins\", \"58-75mins\", \"70-85mins\", \"60-65mins\", \"60-68mins\", \"68-80mins\") ~ \"Second Half\",\n    TRUE ~ Period.Name  # keeps original period names for the rest\n  ))\n\n\n# Filter the dataset to retain only the maximum velocity observation per player, per activity, and per half\nfiltered_max_speed_df &lt;- master_df %&gt;%\n    # Remove Goal Keeper data since they would skew the data\n    filter(Position.Name != \"Goal Keeper\") %&gt;%\n    # Retain only observations where Maximum.Velocity is at least 10\n  filter(Maximum.Velocity &gt;= 10) %&gt;%\n  group_by(Player.Name, Activity_Name, Period.Name.Halves) %&gt;%\n  filter(Maximum.Velocity == max(Maximum.Velocity, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\n# Filter data to include only rows where Period.Name.Halves is \"First Half\" or \"Second Half\"\nfiltered_df_halves &lt;- filtered_max_speed_df %&gt;% filter(Period.Name.Halves %in% c(\"First Half\", \"Second Half\"))\n\n# Boxplot comparing max speed between the two halves\nggplot(filtered_df_halves, aes(x = Period.Name.Halves, y = Maximum.Velocity, fill = Period.Name.Halves)) +\n  geom_boxplot() +\n  labs(title = \"Comparison of Max Speed in First Half vs Second Half\",\n       x = \"Half\",\n       y = \"Max Speed (mph)\") +  \n  theme(legend.position = \"none\")\n\n\n\n# Group by Activity and Period.Name.Halves, then find the top 3 players by maximum velocity\ntop_players_by_activity &lt;- filtered_df_halves %&gt;%\n  group_by(Activity_Name, Period.Name.Halves) %&gt;%\n  top_n(3, Maximum.Velocity) %&gt;%\n  ungroup()\n\n# Count the number of times each player is in the top 3 for the first half\nplayer_counts_first_half &lt;- top_players_by_activity %&gt;%\n  filter(Period.Name.Halves == \"First Half\") %&gt;%  # filter for \"First Half\" only\n  group_by(Player.Name, Period.Name.Halves) %&gt;%\n  summarise(Times_in_Top_3 = n()) %&gt;%\n  arrange(desc(Times_in_Top_3), Player.Name)\n\n`summarise()` has grouped output by 'Player.Name'. You can override using the\n`.groups` argument.\n\n# Count the number of times each player is in the top 3 for the first half\nplayer_counts_second_half &lt;- top_players_by_activity %&gt;%\n  filter(Period.Name.Halves == \"Second Half\") %&gt;%\n  group_by(Player.Name, Period.Name.Halves) %&gt;%\n  summarise(Times_in_Top_3 = n()) %&gt;%\n  arrange(desc(Times_in_Top_3), Player.Name)\n\n`summarise()` has grouped output by 'Player.Name'. You can override using the\n`.groups` argument.\n\nprint(player_counts_first_half)\n\n# A tibble: 24 × 3\n# Groups:   Player.Name [24]\n   Player.Name Period.Name.Halves Times_in_Top_3\n   &lt;chr&gt;       &lt;chr&gt;                       &lt;int&gt;\n 1 Player_14   First Half                     22\n 2 Player_17   First Half                     17\n 3 Player_3    First Half                     14\n 4 Player_4    First Half                     11\n 5 Player_7    First Half                     11\n 6 Player_19   First Half                      9\n 7 Player_12   First Half                      8\n 8 Player_15   First Half                      7\n 9 Player_10   First Half                      6\n10 Player_20   First Half                      6\n# ℹ 14 more rows\n\nprint(player_counts_second_half)\n\n# A tibble: 24 × 3\n# Groups:   Player.Name [24]\n   Player.Name Period.Name.Halves Times_in_Top_3\n   &lt;chr&gt;       &lt;chr&gt;                       &lt;int&gt;\n 1 Player_14   Second Half                    19\n 2 Player_4    Second Half                    14\n 3 Player_12   Second Half                    12\n 4 Player_17   Second Half                    12\n 5 Player_7    Second Half                    12\n 6 Player_19   Second Half                    11\n 7 Player_21   Second Half                     8\n 8 Player_26   Second Half                     7\n 9 Player_3    Second Half                     7\n10 Player_11   Second Half                     6\n# ℹ 14 more rows\n\n# Extract top 5 player names for each half\ntop_5_names_first &lt;- player_counts_first_half$Player.Name[1:5]\ntop_5_names_second &lt;- player_counts_second_half$Player.Name[1:5]\n\n# Combine and get unique names\ntop_5_names_combined &lt;- unique(c(top_5_names_first, top_5_names_second))\n\n# Filter original data\nfiltered_first_half &lt;- player_counts_first_half %&gt;% filter(Player.Name %in% top_5_names_first)\nfiltered_second_half &lt;- player_counts_second_half %&gt;% filter(Player.Name %in% top_5_names_second)\n\n# Combine the data\ncombined_filtered_data &lt;- rbind(filtered_first_half, filtered_second_half)\n\n# Create the bar chart\nggplot(combined_filtered_data, aes(x = Period.Name.Halves, y = Times_in_Top_3, fill = Player.Name)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  labs(title = \"Top 5 Players Who Appeared in Top 3 Max Speeds by Half\",\n       x = \"Half\",\n       y = \"Times in Top 3\") +\n  theme_minimal()\n\n\n\n# Extract top speeds for each player and each half\ntop_speeds_by_half &lt;- filtered_df_halves %&gt;%\n  group_by(Player.Name) %&gt;%\n  summarise(\n    `First Half Speed` = max(Maximum.Velocity[Period.Name.Halves == \"First Half\"], na.rm = TRUE),\n    `Second Half Speed` = max(Maximum.Velocity[Period.Name.Halves == \"Second Half\"], na.rm = TRUE)\n  )\n\nmelted_data &lt;- top_speeds_by_half %&gt;%\n  gather(key = \"Half\", value = \"Speed\", `First Half Speed`, `Second Half Speed`)\n\n# Spaghetti plot of best first half speed and best second half speed by player\nggplot(melted_data, aes(x = Half, y = Speed, group = Player.Name, color = Player.Name)) +\n  geom_line(size = 0.5) +\n  geom_point(size = 3) +\n  labs(title = \"Top Observed Velocity: First Half vs Second Half\",\n       x = \"Game Half\",\n       y = \"Top Velocity\") +\n  theme(legend.position = \"none\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\navg_speed_by_half &lt;- filtered_df_halves %&gt;%\n  group_by(Player.Name, Period.Name.Halves) %&gt;%\n  summarise(Average.Velocity = mean(Maximum.Velocity, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'Player.Name'. You can override using the\n`.groups` argument.\n\nmelted_avg_data &lt;- avg_speed_by_half %&gt;%\n  pivot_longer(cols = Average.Velocity, names_to = \"Attribute\", values_to = \"Speed\")\n\n# Create the spaghetti plot\nggplot(melted_avg_data, aes(x = Period.Name.Halves, y = Speed, group = Player.Name, color = Player.Name)) +\n  geom_line(size = 0.5) +\n  geom_point(size = 3) +\n  labs(title = \"Average Observed Velocity: First Half vs Second Half\",\n       x = \"Game Half\",\n       y = \"Average Velocity\") +\n  theme(legend.position = \"none\")\n\n\n\n\nThe “Comparison of Max Speed in First Half vs Second Half” box plot showed that there doesn’t seem to be a big difference in the average speed of players in the first half and second half. Something I could consider is removing players that did not play a full game from the data, since players are often subbed on in the second half. These substitutes could be running faster since they aren’t fatigued yet, so they could be increasing the average. There seems to be a larger range of speed in the second half, which makes sense since players are getting fatigued.\nNext, I was interested in looking at the individual player level. I took the frequency of players that appeared in the top 3 max speed values per activity. “Player_14” is clearly the fastest player, since he appears in the top 3 the most times out of anyone. I made a stacked box plot looking at the five players that appeared in the top 3 for maximum velocity the most number of times. Four of the players appear in the top 3 the most times for both the first half and second half, but player 3 appeared in the top 3 the third most times for first half and player 12 appeared in the top 3 the third most times for the second half. That tells me that player 12 might be a second half substitute often while player 3 gets subbed off in the second half.\nI then made a spaghetti plot looking at the top recorded velocity for the first half vs second half for each player to see if there is a difference in performance between halves. Interestingly, the trend seems to be that players achieve higher maximum velocities in the second half of games. That makes sense, because player’s might be experience fatigue and might make errors where they have to achieve very high speeds to deal with counter attacks. I made a similar spaghetti plot, except with average velocity across all activities. Now, the trend seems to be the opposite.\n\n\nIn June of 2023, the LA Galaxy U17 team won the MLS Next Tournament. In order to hoist the trophy, they played 5 matches in 7 days in very difficult and humid conditions in Dallas, Texas. To perform an analysis on this data, I had to subset the master data frame to extract the data for these matches. Then, I calculated the match totals for the following physical metrics: total distance, total high intensity bouts, total player load, total explosive efforts, total sprints, total high speed distance (12-14 mph), total very high speed distance (14-17 mph), and total sprinting distance (17-19 mph). I created a table summarizing this data, and made multiple bar charts.\n\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\n\nfiltered_df_2023_06 &lt;- master_df %&gt;%\n    # Remove Goal Keeper data since they would skew the data\n    filter(Position.Name != \"Goal Keeper\") %&gt;%\n  filter(str_detect(Date, \"^2023-06\"))\n\n# Filtering and aggregating data\nteam_metrics_by_game &lt;- filtered_df_2023_06 %&gt;%\n  filter(Period.Name.Halves %in% c(\"First Half\", \"Second Half\")) %&gt;%\n  group_by(Activity_Name) %&gt;%\n  summarise(\n    Game_Date = min(Date),  # Assuming 'Activity_Date' contains the date of the game\n    Total_Distance = sum(Total.Distance, na.rm = TRUE),\n    Total_High_Intensity_Bouts = sum(Total.High.Intensity.Bouts..THIB., na.rm = TRUE),\n    Total_Player_Load = sum(Total.Player.Load, na.rm = TRUE),\n    Total_Explosive_Efforts = sum(Explosive.Efforts, na.rm = TRUE),\n    Total_Sprints = sum(Number.of.Sprints, na.rm = TRUE),\n    Total_High_Speed_Distance = sum(High.Speed.Distance.12mph.14mph, na.rm = TRUE),\n    Total_Very_High_Speed_Distance = sum(Very.High.Speed.Distance.14mph.17mph, na.rm = TRUE),\n    Total_Sprinting_Distance = sum(Sprinting.Distance.17.19mph, na.rm = TRUE)\n  ) %&gt;%\n  ungroup() %&gt;%\n  arrange(Game_Date)  # Arrange data by the game date in chronological order\n\n\nteam_metrics_by_game$Activity_Name &lt;- factor(team_metrics_by_game$Activity_Name, levels = team_metrics_by_game$Activity_Name[order(team_metrics_by_game$Game_Date)])\n\n# # Create a table with all our sums\n# # Custom column names\n# custom_colnames &lt;- gsub(\"_\", \" \", names(team_metrics_by_game))\n# \n# summary_table &lt;- kable(team_metrics_by_game, col.names = custom_colnames) %&gt;%\n#   kable_styling(full_width = F, position = \"center\",\n#                 latex_options = c(\"striped\", \"scale_down\"))\n# print(summary_table)\n\n\n# Plotting Total Distance\nggplot(team_metrics_by_game, aes(x = Activity_Name, y = Total_Distance, fill = Activity_Name)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set3\") +\n  labs(title = \"Total Distance Covered for Each Game\",\n       x = \"Game\",\n       y = \"Total Distance\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n# Plotting Total High Intensity Bouts\nggplot(team_metrics_by_game, aes(x = Activity_Name, y = Total_High_Intensity_Bouts, fill = Activity_Name)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set3\") +\n  labs(title = \"Total High Intensity Bouts for Each Game\",\n       x = \"Game\",\n       y = \"Total High Intensity Bouts\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n# Plotting Total Sprints\nggplot(team_metrics_by_game, aes(x = Activity_Name, y = Total_Sprints, fill = Activity_Name)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set3\") +\n  labs(title = \"Total Sprints for Each Game\",\n       x = \"Game\",\n       y = \"Total Sprints\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n# Plotting Total Explosive Efforts\nggplot(team_metrics_by_game, aes(x = Activity_Name, y = Total_Explosive_Efforts, fill = Activity_Name)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set3\") +\n  labs(title = \"Total Explosive Efforts for Each Game\",\n       x = \"Game\",\n       y = \"Total Explosive Efforts\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n# Plotting Total Player Load with a different color palette\nggplot(team_metrics_by_game, aes(x = Activity_Name, y = Total_Player_Load, fill = Activity_Name)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set3\") +\n  scale_fill_brewer(palette = \"Set3\") +  # Change this to apply different palettes\n  labs(title = \"Total Player Load for Each Game\",\n       x = \"Game\",\n       y = \"Total Player Load\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n# Plotting Stacked Bar Chart\nggplot(team_metrics_by_game, aes(x = Activity_Name)) +\n  geom_bar(aes(y = Total_High_Speed_Distance, fill = \"High Speed Distance (12-14mph)\"), stat = \"identity\") +\n  geom_bar(aes(y = Total_Very_High_Speed_Distance, fill = \"Very High Speed Distance (14-17mph)\"), stat = \"identity\", position = \"stack\") +\n  geom_bar(aes(y = Total_Sprinting_Distance, fill = \"Sprinting Distance (17-19mph)\"), stat = \"identity\", position = \"stack\") +\n  labs(title = \"Distribution of Speed Ranges for Each Game\",\n       x = \"Game\",\n       y = \"Total Distance\",\n       fill = \"Sprinting Speed\") +   # Added legend title here\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"High Speed Distance (12-14mph)\" = \"pink\",\n                               \"Very High Speed Distance (14-17mph)\" = \"orange\",\n                               \"Sprinting Distance (17-19mph)\" = \"red\"))\n\n\n\n\n\nI included a screenshot of the table I made using Kable because I could not get it to render correctly in the HTML no matter what I did, including changing to R markdown. I kept the code, but commented it out.\nWhen looking at total distance covered, there doesn’t seem to be a decrease as the matches progress. Interestingly, the first match had the most sprints, and almost the highest high speed running distance. This is expected since this was the first match of the tournament. There was a noticeable dip in the second match, but this was played the day after the first match. There seemed to be some affects of fatigue in this match. The high speed running distance was the lowest of the tournament. The players also completed the fewest number of sprints in this match. There is also a dip in the number of sprints in the last match, which seems to be an affect of accumulated fatigue. Overall, all of the physical metrics looked at here are have comparable values. When looking at the distribution of speed ranges for each match, there was a noticeable decrease in high speed running in the second match (the one with the least rest) and the last match, again probably due to accumulated fatigue. The distribution of sprinting speeds seems to be fairly similar between matches. As expected, players cover the most distance at high speed, and a small amount of distance at “very” high speeds and sprinting speed.\n\n\n\n\nFrom my analysis, I was able to get a better understanding of how fatigue affects physical metrics measured by Catapult devices. In my analysis of maximum velocity on the player level, I found that fatigue within a single match does not seem to affect whether players will hit a high maximum velocity. The average maximum velocity for the team is slightly higher in the first half and in the second half, which is expected. Intra-player differences in maximum velocity are very low between the first half and the second half. Furthermore, in my analysis of the MLS Next Tournament, I found that there was not a large impact of accumulated fatigue. The distribution of different sprinting speed distances was similar between the games (i.e. player’s did not seem to be sprinting less as the tournament progressed). That’s must mean that players are good at recovering and have good fitness. The matches that seemed the most affected by fatigue were the second match and the last match. As discussed above, that is expected because the second match was played the day after the first match. All of the other matches had at least one day’s rest in between. The last match presumably had lower values due to accumulated fatigue. In conclusion, fatigue definitely has an effect on player’s physical performance, but this needs to be analyzed further, and it varies on a case-by-case basis. High performing athletes seem to be very good at recovering quickly and minimizing the effects of fatigue.\n\nlibrary(dplyr)\n\n# Assuming your dataframe is called df and the columns are named 'Player.Name' and 'Maximum.Velocity'\nmax_speed_by_player &lt;- master_df %&gt;%\n  group_by(Player.Name) %&gt;%\n  summarise(Max_Speed = max(Maximum.Velocity, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\n# Assuming 'Identifier' in name_mapping matches 'Player.Name' in max_speed_by_player\nmax_speed_with_names &lt;- max_speed_by_player %&gt;%\n  left_join(name_mapping, by = c(\"Player.Name\" = \"Identifier\")) %&gt;%\n  select(Original_Name, Max_Speed)\n\n# View the results\nmax_speed_with_names\n\n# A tibble: 35 × 2\n   Original_Name      Max_Speed\n   &lt;chr&gt;                  &lt;dbl&gt;\n 1 Gabriel Arnold          17.9\n 2 Gustavo Gonzalez        18.7\n 3 Ryker Joutz             19.2\n 4 Allan Legaspi           20.6\n 5 Marcus Lightbourne      19.2\n 6 Julian Placias          20.7\n 7 Paulo Rudisill          19.5\n 8 Nico Schelotto          18.6\n 9 Harbor Miller           19.4\n10 Nathan Nava             17.7\n# ℹ 25 more rows\n\nlibrary(readxl)\n# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file\nplayer_data &lt;- read_excel(\"/Users/sylwialipior/Downloads/pm566-01-lab/Academy Data.xlsx\")\n\n# Create a new 'Original_Name' column by concatenating 'First_Name' and 'Last_Name'\nplayer_data &lt;- player_data %&gt;%\n  mutate(Original_Name = paste(First_Name, Last_Name))\n\n\n# Join the player data with max speed data\n# Make sure the key column names match those in your actual dataframes\ncombined_data &lt;- player_data %&gt;%\n  left_join(max_speed_with_names, by = 'Original_Name')\n\nlibrary(writexl)\n# Replace 'path_to_new_excel_file.xlsx' with the desired path for the new Excel file\nwrite_xlsx(combined_data, '/Users/sylwialipior/Downloads/pm566-01-lab/Academy Data_updated.xlsx')\n\n# Continuing from the previous combined_data dataframe\ncombined_data &lt;- combined_data %&gt;%\n  mutate(\n    Height_m = Height / 100, # Convert height from centimeters to meters\n    Weight_kg = Weight * 0.453592, # Convert weight from pounds to kilograms\n    BMI = Weight_kg / (Height_m^2) # Calculate BMI\n  )\n\n# View the first few rows to confirm the BMI column has been added\nhead(combined_data)\n\n# A tibble: 6 × 22\n  Date                Last_Name   First_Name Birth_Year Birth_Month Gender Team \n  &lt;dttm&gt;              &lt;chr&gt;       &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;\n1 2022-08-01 00:00:00 Dalgado     Riley            2006 August      M      U17  \n2 2022-08-01 00:00:00 Garcia      Emiliano         2006 January     M      U17  \n3 2022-08-01 00:00:00 Legaspi     Allan            2006 January     M      U17  \n4 2022-08-01 00:00:00 Placias     Julian           2006 April       M      U17  \n5 2022-08-01 00:00:00 Dunbar      Adam             2007 February    M      U17  \n6 2022-08-01 00:00:00 Lightbourne Marcus           2006 July        M      U17  \n# ℹ 15 more variables: Height &lt;dbl&gt;, Weight &lt;dbl&gt;, Body_Fat &lt;lgl&gt;, Yo_Yo &lt;dbl&gt;,\n#   ten_meter &lt;dbl&gt;, `20m` &lt;dbl&gt;, thirty_meter &lt;dbl&gt;, five_ten_five_L &lt;dbl&gt;,\n#   five_ten_five_R &lt;dbl&gt;, CMJ &lt;chr&gt;, Original_Name &lt;chr&gt;, Max_Speed &lt;dbl&gt;,\n#   Height_m &lt;dbl&gt;, Weight_kg &lt;dbl&gt;, BMI &lt;dbl&gt;\n\nlibrary(dplyr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\ncombined_data &lt;- combined_data %&gt;%\n  mutate(\n    # Convert 'Birth_Month' to a numeric value\n    Birth_Month_Num = match(Birth_Month, month.name),  # Assumes 'Birth_Month' is a three-letter abbreviation\n    Birthdate = make_date(Birth_Year, Birth_Month_Num, 1),\n    # Make sure 'Date' is a Date object; use the appropriate lubridate function if the format is different\n    Test_Date = as.Date(Date),  # Replace with mdy(Date), dmy(Date), etc., as appropriate\n    Age_at_Testing = as.numeric(difftime(Test_Date, Birthdate, units = \"weeks\")) / 52.25\n  )\n\n# View the first few rows to confirm the Age_at_Testing column has been added\nhead(combined_data)\n\n# A tibble: 6 × 26\n  Date                Last_Name   First_Name Birth_Year Birth_Month Gender Team \n  &lt;dttm&gt;              &lt;chr&gt;       &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;\n1 2022-08-01 00:00:00 Dalgado     Riley            2006 August      M      U17  \n2 2022-08-01 00:00:00 Garcia      Emiliano         2006 January     M      U17  \n3 2022-08-01 00:00:00 Legaspi     Allan            2006 January     M      U17  \n4 2022-08-01 00:00:00 Placias     Julian           2006 April       M      U17  \n5 2022-08-01 00:00:00 Dunbar      Adam             2007 February    M      U17  \n6 2022-08-01 00:00:00 Lightbourne Marcus           2006 July        M      U17  \n# ℹ 19 more variables: Height &lt;dbl&gt;, Weight &lt;dbl&gt;, Body_Fat &lt;lgl&gt;, Yo_Yo &lt;dbl&gt;,\n#   ten_meter &lt;dbl&gt;, `20m` &lt;dbl&gt;, thirty_meter &lt;dbl&gt;, five_ten_five_L &lt;dbl&gt;,\n#   five_ten_five_R &lt;dbl&gt;, CMJ &lt;chr&gt;, Original_Name &lt;chr&gt;, Max_Speed &lt;dbl&gt;,\n#   Height_m &lt;dbl&gt;, Weight_kg &lt;dbl&gt;, BMI &lt;dbl&gt;, Birth_Month_Num &lt;int&gt;,\n#   Birthdate &lt;date&gt;, Test_Date &lt;date&gt;, Age_at_Testing &lt;dbl&gt;\n\n\nLinear Regression\n\n# Let's assume your combined data with max speed, BMI, and age is named 'combined_data'\nmodel &lt;- lm(Max_Speed ~ Age_at_Testing + Height_m + Weight_kg + thirty_meter + ten_meter, data = combined_data)\nsummary(model)\n\n\nCall:\nlm(formula = Max_Speed ~ Age_at_Testing + Height_m + Weight_kg + \n    thirty_meter + ten_meter, data = combined_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.9410 -0.4834 -0.1384  0.4963  1.0577 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    64.08743   11.33309   5.655 1.88e-05 ***\nAge_at_Testing -0.34688    0.32666  -1.062    0.302    \nHeight_m       -1.65461    3.85506  -0.429    0.673    \nWeight_kg      -0.02074    0.03461  -0.599    0.556    \nthirty_meter   -8.17774    1.35102  -6.053 8.03e-06 ***\nten_meter      -0.16515    0.89072  -0.185    0.855    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6928 on 19 degrees of freedom\n  (140 observations deleted due to missingness)\nMultiple R-squared:  0.7461,    Adjusted R-squared:  0.6793 \nF-statistic: 11.17 on 5 and 19 DF,  p-value: 3.963e-05\n\nlibrary(caret)\n\nLoading required package: lattice\n\nlibrary(dplyr)\n\n# Filter out rows with NA in the thirty_meter column\ncombined_data_filtered &lt;- combined_data %&gt;% \n  filter(!is.na(thirty_meter) & !is.na(Max_Speed) & !is.na(ten_meter))\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Split data into training (75%) and test sets (25%)\ntrainIndex &lt;- createDataPartition(combined_data_filtered$Max_Speed, p = 0.8, list = FALSE, times = 1)\ntrainData &lt;- combined_data_filtered[trainIndex, ]\ntestData &lt;- combined_data_filtered[-trainIndex, ]\n\n# Fit the linear model on the training set\nmodel &lt;- lm(Max_Speed ~ Age_at_Testing + Height_m + Weight_kg + thirty_meter + ten_meter, data = trainData)\n\n# Summarize the model\nsummary(model)\n\n\nCall:\nlm(formula = Max_Speed ~ Age_at_Testing + Height_m + Weight_kg + \n    thirty_meter + ten_meter, data = trainData)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0378 -0.3590 -0.1233  0.5099  1.0563 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    68.699448  14.266118   4.816 0.000227 ***\nAge_at_Testing -0.412015   0.465008  -0.886 0.389581    \nHeight_m       -3.946296   4.228569  -0.933 0.365473    \nWeight_kg      -0.006261   0.038711  -0.162 0.873675    \nthirty_meter   -8.205729   1.545447  -5.310 8.74e-05 ***\nten_meter      -0.397217   0.944680  -0.420 0.680098    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7118 on 15 degrees of freedom\nMultiple R-squared:  0.7681,    Adjusted R-squared:  0.6907 \nF-statistic: 9.934 on 5 and 15 DF,  p-value: 0.00024\n\n# Predict on the test set\npredictions &lt;- predict(model, newdata = testData)\n\n# Calculate performance metrics, such as Mean Squared Error (MSE)\nmse &lt;- mean((testData$Max_Speed - predictions)^2)\nprint(paste(\"Mean Squared Error: \", mse))\n\n[1] \"Mean Squared Error:  0.446101767664014\"\n\n# Optionally, compare actual max speeds vs predicted max speeds\ncomparison &lt;- data.frame(Actual = testData$Max_Speed, Predicted = predictions)\nprint(comparison)\n\n    Actual Predicted\n1 20.12038  19.57192\n2 17.85323  18.80160\n3 18.18696  18.67113\n4 19.08000  18.48858\n\nlibrary(car)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n# Fit the linear model without the 'ten_meter' variable\nmodel_without_ten &lt;- lm(Max_Speed ~ Age_at_Testing + Height_m + Weight_kg + thirty_meter, data = trainData)\n\n# Calculate VIF for the model\nvif_results &lt;- vif(model_without_ten)\nprint(vif_results)\n\nAge_at_Testing       Height_m      Weight_kg   thirty_meter \n      2.625076       5.258976       5.661624       2.201260 \n\n# Alternatively, to get a nicely formatted output\nvif_df &lt;- data.frame(Variable = names(vif_results), VIF = vif_results)\nprint(vif_df)\n\n                     Variable      VIF\nAge_at_Testing Age_at_Testing 2.625076\nHeight_m             Height_m 5.258976\nWeight_kg           Weight_kg 5.661624\nthirty_meter     thirty_meter 2.201260"
  },
  {
    "objectID": "PM566_Midterm.html#introduction",
    "href": "PM566_Midterm.html#introduction",
    "title": "Midterm Project",
    "section": "",
    "text": "Catapult devices are GPS trackers worn by athletes. Wearable-based tracking technologies are used throughout sport to support performance monitoring. In addition to GPS capability, these devices contain inertial sensors comprising of an accelerometer (to measure acceleration forces), a gyroscope (to measure rotation), and a magnetometer (to measure body orientation). Inertial sensors collect data in three axes, or directions, allowing sensitive ‘maps’ of athlete movements and actions to be created. For Catapult’s website, they claim: “The combination of the wearable tracking device and the inertial sensors creates a powerful athlete monitoring tool that ensures that key performance decisions are always supported with objective data.” The sports performance department at LA Galaxy uses Catapult data to make decisions about performance readiness, rehabilitation, and training prescription.\nThis data is Catapult data collected over the course of the U17 2022-2023 season. I will specifically be look at U17 game data for that season. As a student in the USC Sports Science program and an intern at the LA Galaxy Sports Performance Department, I’ve had the opportunity to assist with collecting this data since January 2023. This data is typically visualized using either Catapult’s Cloud where they offer many widgets to visualize data, or an internal athlete management system. LA Galaxy has been developing an athlete management system using Microsoft Azure. They export the data from Catapult and import it to Azure and have customized many different dashboards to visualize data. For this project, I decided to export CSVs directly from Catapult and try to wrangle the data myself.\nCatapult data is collected at every training session and game. The players wear the devices on vests produced by Catapults and the GPS units are stored in a secure pouch on the back of the vest. During training or games, a member of the sport performance department will have an iPad which has the Vector app created by Catapult. The Vector app allows the user to input information about the training session or game, and it produces a live view of the Catapult data per player. The user can start and stop “Periods” based on training drills and which players are participating. After training, all the units are collected, put into a dock, and uploaded to a computer. This data is then available in the Cloud and can be exported to the athlete management system for further visualization.\nWhen thinking about this data, my research question became: does fatigue affect player’s physical performance in soccer matches? More specifically, are players less physically productive when they are tired? To answer this question, I looked at the data at a few levels. To start off, I look at the difference in player’s maximum velocities in the first half of games vs the second half. Then, I look at a string of five games in seven games that the team played in difficult conditions in the MLS Next Tournament, which was played in June of this year."
  },
  {
    "objectID": "PM566_Midterm.html#methods",
    "href": "PM566_Midterm.html#methods",
    "title": "Midterm Project",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n# This is where I stored the downloaded CSVs from Catapult\nsetwd(\"/Users/sylwialipior/Downloads/pm566-01-lab/U17 2022-2023 Data\")\n\n# Get a list of all CSV files containing \"_GD_\"\nfilenames &lt;- list.files(pattern = \"_GD_.*\\\\.csv$\")\n\n\n\n\nWhen you export bulk CSVs from Catapult, you get observations for every player involved in the session for 1699 variables. A lot of that data is a little redundant, but I wrote a function to subset the data with only around 34 variables of interest to make it more manageable. The CSVs don’t have the activity name easily accessible, so I wrote a function to extract the names from the names of the CSV files. I then wrote a for loop to read in all the data (~57 CSVs which corresponds to data from 57 games), making a new variable for the date of the session, and a new variable for the activity name. Finally, I de-identified the data since the data contains player names.\n\nsetwd(\"/Users/sylwialipior/Downloads/pm566-01-lab/U17 2022-2023 Data\")\n\n# List of desired variables\ndesired_variables &lt;- c(\n    \"Player.Name\", \"Period.Name\", \"Period.Number\", \"Position.Name\", \n    \"Total.Duration\", \"Total.Distance\", \"Total.Player.Load\", \n    \"Player.Load.Per.Minute\", \"Player.Load.Per.Metre\", \"Meterage.Per.Minute\", \n    \"Maximum.Velocity\", \"High.Speed.Distance.12mph.14mph\", \n    \"Very.High.Speed.Distance.14mph.17mph\", \"Sprinting.Distance.17.19mph\", \n    \"Supra.Max.Velocity..19mph\", \"Number.of.Sprints\", \n    \"Velocity.Band.7.Average.Effort.Count\", \"Velocity.Band.8.Average.Effort.Count\", \n    \"Max.Vel....Max.\", \"Profile.Max.Velocity\", \"Explosive.Efforts\", \n    \"HSD.min\", \"Total.High.Intensity.Bouts..THIB.\", \"Maximal.High.Intensity.Bouts..MHIB.\", \n    \"Accels..2.5...3.m.s.s.\", \"Accels..3...3.5.m.s.s.\", \"Accels....3.5.m.s.s.\", \n    \"Decels...2.5....3.m.s.s\", \"Decels...3....3.5.m.s.s.\", \"Decels.....3.5.m.s.s.\", \n    \"Acceleration.Density\", \"Acceleration.Density.Index\"\n)\n\n#Function to read only columns of interest\nread_selected_columns &lt;- function(filename) {\n    # Read the entire CSV\n    data &lt;- read.csv(filename, skip = 9, header = TRUE, sep = \",\")\n    \n    # Subset the data to keep only the desired columns\n    data &lt;- data[, desired_variables, drop = FALSE]\n    \n    return(data)\n}\n\n# Function to extract and format the activity name from filename\nextract_activity_name &lt;- function(filename) {\n    # Extract the part of the filename after U17 and before the file extension\n    name_part &lt;- sub(\".*U17_([^\\\\.]+)\\\\.csv$\", \"\\\\1\", filename)\n    \n    # Replace underscores with spaces\n    activity_name &lt;- gsub(\"_\", \" \", name_part)\n    \n    # Prepend \"U17 \" to the modified name\n    paste(\"U17\", activity_name)\n}\n\n# Initialize an empty list to hold individual data frames\ndata_frames &lt;- list()\n\n# Loop through each file, read it, and add to the list\nfor (filename in filenames) {\n    df &lt;- read_selected_columns(filename)\n    \n    #Extract the activity name from the filename\n    activity_name &lt;- extract_activity_name(filename)\n    \n    # Extract date information from the filename\n    date_string &lt;- substr(filename, 1, 10) # Assuming the date is always the first 10             characters\n    date_obj &lt;- as.Date(date_string, format = \"%Y_%m_%d\")\n    \n    # Add new columns for date and activity name\n    df$Date &lt;- date_obj\n    df$Activity_Name &lt;- activity_name\n    \n    data_frames[[filename]] &lt;- df  # using filename as list name just for clarity, can use any     naming convention\n}\n\n# Combine all data frames into one master data frame\nmaster_df &lt;- bind_rows(data_frames)\n\n## De-identifying the data\n# Generate a unique identifier for each player name\nunique_players &lt;- unique(master_df$Player.Name)\nname_mapping &lt;- data.frame(\n    Original_Name = unique_players,\n    Identifier = paste0(\"Player_\", seq_along(unique_players))\n)\n\n# Replace the actual player names with the generated identifiers\nmaster_df$Player.Name &lt;- name_mapping$Identifier[match(master_df$Player.Name, name_mapping$Original_Name)]"
  },
  {
    "objectID": "PM566_Midterm.html#initial-visualization-of-the-data",
    "href": "PM566_Midterm.html#initial-visualization-of-the-data",
    "title": "Midterm Project",
    "section": "",
    "text": "Next, I wanted to make sure the data looks how I would expect it to. Since the session names are inputted by staff, there is some room for error, and I wanted to make sure I have only game data here. To accomplish this, I decided to plot maximum velocity for each activity by month.\n\n# Extract month and year from the Date column to create a new 'Month' column\nmaster_df$Month &lt;- format(master_df$Date, \"%m\")\n\n# List of unique months\nunique_months &lt;- unique(master_df$Month)\n\n# # Loop through each month, create a plot, and then add a page break\n# for (month in unique_months) {\n#   sub_df &lt;- master_df[master_df$Month == month, ]\n#   \n#   print(\n#     ggplot(sub_df, aes(x = Activity_Name, y = Maximum.Velocity, fill = Activity_Name)) +\n#       geom_boxplot() +\n#       theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n#       labs(title = paste(\"Max Speeds of Players for Month\", month),\n#            x = \"Activity\",\n#            y = \"Max Speed (mph)\") +  \n#       theme(legend.position = \"none\")\n#   )\n#   \n#   # Add a page break after each plot\n#   cat(\"\\\\newpage\")\n# }\n\n\n# Filter out the unwanted activities\nmaster_df &lt;- master_df %&gt;%\n  filter(!(Activity_Name %in% c(\"U17 GD vs RSL\", \"U17 GD Pre Season Day 2\")))\n\nFrom looking at the initial box plots, I figured out that there is some data in the set that doesn’t belong. Specifically, “U17 GD vs RSL” seems to have an issue with the GPS data since the maximum velocities are so low, so I decided to remove that data. In addition, the maximum velocities for “U17 GD Pre Season Day 2” are much lower than expected. Once I looked at the period names, I realized that this is data from a training session that was mislabeled as a game, so I removed it from the data set. I included the code to produce these box plots, but decided not to render here, because I did not use them for further analysis."
  },
  {
    "objectID": "PM566_Midterm.html#player-load-scatter-plots",
    "href": "PM566_Midterm.html#player-load-scatter-plots",
    "title": "Midterm Project",
    "section": "",
    "text": "For some more initial visualization, I decided to look at the relationship between “Player Load”, which is defined by Catapult as “the sum of the accelerations across all axes of the internal tri-axial accelerometer during movement”, and a few other physical metrics. Specifically, I looked at scatterplot of Player Load vs Total Distance Covered, Total Number of Sprints, Explosive Efforts, and Total High Intensity Bouts.\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(knitr)\n\n# Filter data for when Period.Name is \"Session\" and for games in September\nfiltered_df &lt;- master_df %&gt;% \n               filter(Period.Name == \"Session\")\n\nggplot(filtered_df, aes(x = Total.Player.Load, y = Total.Distance, color = Player.Name)) +\n    geom_point() +\n    labs(title = \"Scatterplot of Player Load vs. Distance Covered\", x = \"Total Player Load\",\n         y = \"Total Distance\") +\n    theme(legend.position = \"none\")\n\n\n\nggplot(filtered_df, aes(x = Total.Player.Load, y = Number.of.Sprints, color = Player.Name)) +\n    geom_point() +\n    labs(title = \"Scatterplot of Player Load vs. Total Number of Sprints\", x = \"Total Player Load\",\n         y = \"Total Number of Sprints\") +\n    theme(legend.position = \"none\")\n\n\n\nggplot(filtered_df, aes(x = Total.Player.Load, y = Explosive.Efforts, color = Player.Name)) +\n    geom_point() +\n    labs(title = \"Scatterplot of Player Load vs. Explosive Efforts\", x = \"Total Player Load\",\n         y = \"Explosive Efforts\") +\n    theme(legend.position = \"none\")\n\n\n\nggplot(filtered_df, aes(x = Total.Player.Load, y = Total.High.Intensity.Bouts..THIB., color = Player.Name)) +\n    geom_point() +\n    labs(title = \"Scatterplot of Player Load vs. Total High Intensity Bouts\", x = \"Total Player Load\",\n         y = \"Total High Intensity Bouts\") +\n    theme(legend.position = \"none\")\n\n\n\n\nAfter looking at the plots, as expected there is a strong positive correlation between Player Load and all the other physical metrics. In other words, as a player covers more distance, or performs more sprints, explosive efforts, or high intensity bouts, their player load is expected to be higher."
  },
  {
    "objectID": "PM566_Midterm.html#maximum-velocity-analysis",
    "href": "PM566_Midterm.html#maximum-velocity-analysis",
    "title": "Midterm Project",
    "section": "",
    "text": "I thought it would be interesting to analyze maximum velocity from the dataset. Unfortunately, the data is a little difficult, because there are various Period Names that could signify either First Half or Second Half game data. Therefore, I used mutate to add a variable called “Period.Name.Halves” to denote which observations are from the first half vs the second half. I also removed Goal Keeper data, since their data looks very different from field players due to the nature of their position. I added a threshold of 10mph for speed, to make sure that I am actually using game data, and not some other potentially mislabeled data. I then visualized the maximum velocity data in a few different ways.\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n\n# Mutate new variable based on criteria\nmaster_df &lt;- master_df %&gt;%\n  mutate(Period.Name.Halves = case_when(\n    Period.Name %in% c(\"1st Half\", \"0- 10 min\", \"10-45min\", \"0-15mins\", \"15-30mins\", \"30-45mins\") ~ \"First Half\",\n    Period.Name %in% c(\"2nd Half\", \"45-60mins\", \"60-70mins\", \"70-90mins\", \"45-70mins\", \"70-75mins\", \n                       \"75-90mins\", \"66-80min\", \"80-85min\", \"85-90min\", \"45-50mins\", \"50-65mins\", \"60-75mins\",\n                       \"45-75mins\", \"75-83min\", \"83-90min\", \"45-55mins\", \"55-60mins\", \"60-72mins\", \"72-90mins\",\n                       \"56-60mins\", \"55-70mins\", \"70-77mins\", \"77-90mins\", \"70-74mins\", \"74-83mins\", \"83-90mins\",\n                       \"60-69mins\", \"69-77mins\", \"77-83mins\", \"75-78mins\", \"78-85mins\", \"85-90mins\", \"75-80mins\",\n                       \"80-90mins\", \"45-58mins\", \"58-75mins\", \"70-85mins\", \"60-65mins\", \"60-68mins\", \"68-80mins\") ~ \"Second Half\",\n    TRUE ~ Period.Name  # keeps original period names for the rest\n  ))\n\n\n# Filter the dataset to retain only the maximum velocity observation per player, per activity, and per half\nfiltered_max_speed_df &lt;- master_df %&gt;%\n    # Remove Goal Keeper data since they would skew the data\n    filter(Position.Name != \"Goal Keeper\") %&gt;%\n    # Retain only observations where Maximum.Velocity is at least 10\n  filter(Maximum.Velocity &gt;= 10) %&gt;%\n  group_by(Player.Name, Activity_Name, Period.Name.Halves) %&gt;%\n  filter(Maximum.Velocity == max(Maximum.Velocity, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\n# Filter data to include only rows where Period.Name.Halves is \"First Half\" or \"Second Half\"\nfiltered_df_halves &lt;- filtered_max_speed_df %&gt;% filter(Period.Name.Halves %in% c(\"First Half\", \"Second Half\"))\n\n# Boxplot comparing max speed between the two halves\nggplot(filtered_df_halves, aes(x = Period.Name.Halves, y = Maximum.Velocity, fill = Period.Name.Halves)) +\n  geom_boxplot() +\n  labs(title = \"Comparison of Max Speed in First Half vs Second Half\",\n       x = \"Half\",\n       y = \"Max Speed (mph)\") +  \n  theme(legend.position = \"none\")\n\n\n\n# Group by Activity and Period.Name.Halves, then find the top 3 players by maximum velocity\ntop_players_by_activity &lt;- filtered_df_halves %&gt;%\n  group_by(Activity_Name, Period.Name.Halves) %&gt;%\n  top_n(3, Maximum.Velocity) %&gt;%\n  ungroup()\n\n# Count the number of times each player is in the top 3 for the first half\nplayer_counts_first_half &lt;- top_players_by_activity %&gt;%\n  filter(Period.Name.Halves == \"First Half\") %&gt;%  # filter for \"First Half\" only\n  group_by(Player.Name, Period.Name.Halves) %&gt;%\n  summarise(Times_in_Top_3 = n()) %&gt;%\n  arrange(desc(Times_in_Top_3), Player.Name)\n\n`summarise()` has grouped output by 'Player.Name'. You can override using the\n`.groups` argument.\n\n# Count the number of times each player is in the top 3 for the first half\nplayer_counts_second_half &lt;- top_players_by_activity %&gt;%\n  filter(Period.Name.Halves == \"Second Half\") %&gt;%\n  group_by(Player.Name, Period.Name.Halves) %&gt;%\n  summarise(Times_in_Top_3 = n()) %&gt;%\n  arrange(desc(Times_in_Top_3), Player.Name)\n\n`summarise()` has grouped output by 'Player.Name'. You can override using the\n`.groups` argument.\n\nprint(player_counts_first_half)\n\n# A tibble: 24 × 3\n# Groups:   Player.Name [24]\n   Player.Name Period.Name.Halves Times_in_Top_3\n   &lt;chr&gt;       &lt;chr&gt;                       &lt;int&gt;\n 1 Player_14   First Half                     22\n 2 Player_17   First Half                     17\n 3 Player_3    First Half                     14\n 4 Player_4    First Half                     11\n 5 Player_7    First Half                     11\n 6 Player_19   First Half                      9\n 7 Player_12   First Half                      8\n 8 Player_15   First Half                      7\n 9 Player_10   First Half                      6\n10 Player_20   First Half                      6\n# ℹ 14 more rows\n\nprint(player_counts_second_half)\n\n# A tibble: 24 × 3\n# Groups:   Player.Name [24]\n   Player.Name Period.Name.Halves Times_in_Top_3\n   &lt;chr&gt;       &lt;chr&gt;                       &lt;int&gt;\n 1 Player_14   Second Half                    19\n 2 Player_4    Second Half                    14\n 3 Player_12   Second Half                    12\n 4 Player_17   Second Half                    12\n 5 Player_7    Second Half                    12\n 6 Player_19   Second Half                    11\n 7 Player_21   Second Half                     8\n 8 Player_26   Second Half                     7\n 9 Player_3    Second Half                     7\n10 Player_11   Second Half                     6\n# ℹ 14 more rows\n\n# Extract top 5 player names for each half\ntop_5_names_first &lt;- player_counts_first_half$Player.Name[1:5]\ntop_5_names_second &lt;- player_counts_second_half$Player.Name[1:5]\n\n# Combine and get unique names\ntop_5_names_combined &lt;- unique(c(top_5_names_first, top_5_names_second))\n\n# Filter original data\nfiltered_first_half &lt;- player_counts_first_half %&gt;% filter(Player.Name %in% top_5_names_first)\nfiltered_second_half &lt;- player_counts_second_half %&gt;% filter(Player.Name %in% top_5_names_second)\n\n# Combine the data\ncombined_filtered_data &lt;- rbind(filtered_first_half, filtered_second_half)\n\n# Create the bar chart\nggplot(combined_filtered_data, aes(x = Period.Name.Halves, y = Times_in_Top_3, fill = Player.Name)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  labs(title = \"Top 5 Players Who Appeared in Top 3 Max Speeds by Half\",\n       x = \"Half\",\n       y = \"Times in Top 3\") +\n  theme_minimal()\n\n\n\n# Extract top speeds for each player and each half\ntop_speeds_by_half &lt;- filtered_df_halves %&gt;%\n  group_by(Player.Name) %&gt;%\n  summarise(\n    `First Half Speed` = max(Maximum.Velocity[Period.Name.Halves == \"First Half\"], na.rm = TRUE),\n    `Second Half Speed` = max(Maximum.Velocity[Period.Name.Halves == \"Second Half\"], na.rm = TRUE)\n  )\n\nmelted_data &lt;- top_speeds_by_half %&gt;%\n  gather(key = \"Half\", value = \"Speed\", `First Half Speed`, `Second Half Speed`)\n\n# Spaghetti plot of best first half speed and best second half speed by player\nggplot(melted_data, aes(x = Half, y = Speed, group = Player.Name, color = Player.Name)) +\n  geom_line(size = 0.5) +\n  geom_point(size = 3) +\n  labs(title = \"Top Observed Velocity: First Half vs Second Half\",\n       x = \"Game Half\",\n       y = \"Top Velocity\") +\n  theme(legend.position = \"none\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\navg_speed_by_half &lt;- filtered_df_halves %&gt;%\n  group_by(Player.Name, Period.Name.Halves) %&gt;%\n  summarise(Average.Velocity = mean(Maximum.Velocity, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'Player.Name'. You can override using the\n`.groups` argument.\n\nmelted_avg_data &lt;- avg_speed_by_half %&gt;%\n  pivot_longer(cols = Average.Velocity, names_to = \"Attribute\", values_to = \"Speed\")\n\n# Create the spaghetti plot\nggplot(melted_avg_data, aes(x = Period.Name.Halves, y = Speed, group = Player.Name, color = Player.Name)) +\n  geom_line(size = 0.5) +\n  geom_point(size = 3) +\n  labs(title = \"Average Observed Velocity: First Half vs Second Half\",\n       x = \"Game Half\",\n       y = \"Average Velocity\") +\n  theme(legend.position = \"none\")\n\n\n\n\nThe “Comparison of Max Speed in First Half vs Second Half” box plot showed that there doesn’t seem to be a big difference in the average speed of players in the first half and second half. Something I could consider is removing players that did not play a full game from the data, since players are often subbed on in the second half. These substitutes could be running faster since they aren’t fatigued yet, so they could be increasing the average. There seems to be a larger range of speed in the second half, which makes sense since players are getting fatigued.\nNext, I was interested in looking at the individual player level. I took the frequency of players that appeared in the top 3 max speed values per activity. “Player_14” is clearly the fastest player, since he appears in the top 3 the most times out of anyone. I made a stacked box plot looking at the five players that appeared in the top 3 for maximum velocity the most number of times. Four of the players appear in the top 3 the most times for both the first half and second half, but player 3 appeared in the top 3 the third most times for first half and player 12 appeared in the top 3 the third most times for the second half. That tells me that player 12 might be a second half substitute often while player 3 gets subbed off in the second half.\nI then made a spaghetti plot looking at the top recorded velocity for the first half vs second half for each player to see if there is a difference in performance between halves. Interestingly, the trend seems to be that players achieve higher maximum velocities in the second half of games. That makes sense, because player’s might be experience fatigue and might make errors where they have to achieve very high speeds to deal with counter attacks. I made a similar spaghetti plot, except with average velocity across all activities. Now, the trend seems to be the opposite.\n\n\nIn June of 2023, the LA Galaxy U17 team won the MLS Next Tournament. In order to hoist the trophy, they played 5 matches in 7 days in very difficult and humid conditions in Dallas, Texas. To perform an analysis on this data, I had to subset the master data frame to extract the data for these matches. Then, I calculated the match totals for the following physical metrics: total distance, total high intensity bouts, total player load, total explosive efforts, total sprints, total high speed distance (12-14 mph), total very high speed distance (14-17 mph), and total sprinting distance (17-19 mph). I created a table summarizing this data, and made multiple bar charts.\n\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\n\nfiltered_df_2023_06 &lt;- master_df %&gt;%\n    # Remove Goal Keeper data since they would skew the data\n    filter(Position.Name != \"Goal Keeper\") %&gt;%\n  filter(str_detect(Date, \"^2023-06\"))\n\n# Filtering and aggregating data\nteam_metrics_by_game &lt;- filtered_df_2023_06 %&gt;%\n  filter(Period.Name.Halves %in% c(\"First Half\", \"Second Half\")) %&gt;%\n  group_by(Activity_Name) %&gt;%\n  summarise(\n    Game_Date = min(Date),  # Assuming 'Activity_Date' contains the date of the game\n    Total_Distance = sum(Total.Distance, na.rm = TRUE),\n    Total_High_Intensity_Bouts = sum(Total.High.Intensity.Bouts..THIB., na.rm = TRUE),\n    Total_Player_Load = sum(Total.Player.Load, na.rm = TRUE),\n    Total_Explosive_Efforts = sum(Explosive.Efforts, na.rm = TRUE),\n    Total_Sprints = sum(Number.of.Sprints, na.rm = TRUE),\n    Total_High_Speed_Distance = sum(High.Speed.Distance.12mph.14mph, na.rm = TRUE),\n    Total_Very_High_Speed_Distance = sum(Very.High.Speed.Distance.14mph.17mph, na.rm = TRUE),\n    Total_Sprinting_Distance = sum(Sprinting.Distance.17.19mph, na.rm = TRUE)\n  ) %&gt;%\n  ungroup() %&gt;%\n  arrange(Game_Date)  # Arrange data by the game date in chronological order\n\n\nteam_metrics_by_game$Activity_Name &lt;- factor(team_metrics_by_game$Activity_Name, levels = team_metrics_by_game$Activity_Name[order(team_metrics_by_game$Game_Date)])\n\n# # Create a table with all our sums\n# # Custom column names\n# custom_colnames &lt;- gsub(\"_\", \" \", names(team_metrics_by_game))\n# \n# summary_table &lt;- kable(team_metrics_by_game, col.names = custom_colnames) %&gt;%\n#   kable_styling(full_width = F, position = \"center\",\n#                 latex_options = c(\"striped\", \"scale_down\"))\n# print(summary_table)\n\n\n# Plotting Total Distance\nggplot(team_metrics_by_game, aes(x = Activity_Name, y = Total_Distance, fill = Activity_Name)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set3\") +\n  labs(title = \"Total Distance Covered for Each Game\",\n       x = \"Game\",\n       y = \"Total Distance\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n# Plotting Total High Intensity Bouts\nggplot(team_metrics_by_game, aes(x = Activity_Name, y = Total_High_Intensity_Bouts, fill = Activity_Name)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set3\") +\n  labs(title = \"Total High Intensity Bouts for Each Game\",\n       x = \"Game\",\n       y = \"Total High Intensity Bouts\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n# Plotting Total Sprints\nggplot(team_metrics_by_game, aes(x = Activity_Name, y = Total_Sprints, fill = Activity_Name)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set3\") +\n  labs(title = \"Total Sprints for Each Game\",\n       x = \"Game\",\n       y = \"Total Sprints\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n# Plotting Total Explosive Efforts\nggplot(team_metrics_by_game, aes(x = Activity_Name, y = Total_Explosive_Efforts, fill = Activity_Name)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set3\") +\n  labs(title = \"Total Explosive Efforts for Each Game\",\n       x = \"Game\",\n       y = \"Total Explosive Efforts\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n# Plotting Total Player Load with a different color palette\nggplot(team_metrics_by_game, aes(x = Activity_Name, y = Total_Player_Load, fill = Activity_Name)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set3\") +\n  scale_fill_brewer(palette = \"Set3\") +  # Change this to apply different palettes\n  labs(title = \"Total Player Load for Each Game\",\n       x = \"Game\",\n       y = \"Total Player Load\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.text.x = element_text(angle = 45, hjust = 1))\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n# Plotting Stacked Bar Chart\nggplot(team_metrics_by_game, aes(x = Activity_Name)) +\n  geom_bar(aes(y = Total_High_Speed_Distance, fill = \"High Speed Distance (12-14mph)\"), stat = \"identity\") +\n  geom_bar(aes(y = Total_Very_High_Speed_Distance, fill = \"Very High Speed Distance (14-17mph)\"), stat = \"identity\", position = \"stack\") +\n  geom_bar(aes(y = Total_Sprinting_Distance, fill = \"Sprinting Distance (17-19mph)\"), stat = \"identity\", position = \"stack\") +\n  labs(title = \"Distribution of Speed Ranges for Each Game\",\n       x = \"Game\",\n       y = \"Total Distance\",\n       fill = \"Sprinting Speed\") +   # Added legend title here\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"High Speed Distance (12-14mph)\" = \"pink\",\n                               \"Very High Speed Distance (14-17mph)\" = \"orange\",\n                               \"Sprinting Distance (17-19mph)\" = \"red\"))\n\n\n\n\n\nI included a screenshot of the table I made using Kable because I could not get it to render correctly in the HTML no matter what I did, including changing to R markdown. I kept the code, but commented it out.\nWhen looking at total distance covered, there doesn’t seem to be a decrease as the matches progress. Interestingly, the first match had the most sprints, and almost the highest high speed running distance. This is expected since this was the first match of the tournament. There was a noticeable dip in the second match, but this was played the day after the first match. There seemed to be some affects of fatigue in this match. The high speed running distance was the lowest of the tournament. The players also completed the fewest number of sprints in this match. There is also a dip in the number of sprints in the last match, which seems to be an affect of accumulated fatigue. Overall, all of the physical metrics looked at here are have comparable values. When looking at the distribution of speed ranges for each match, there was a noticeable decrease in high speed running in the second match (the one with the least rest) and the last match, again probably due to accumulated fatigue. The distribution of sprinting speeds seems to be fairly similar between matches. As expected, players cover the most distance at high speed, and a small amount of distance at “very” high speeds and sprinting speed."
  },
  {
    "objectID": "PM566_Midterm.html#conclusion",
    "href": "PM566_Midterm.html#conclusion",
    "title": "Midterm Project",
    "section": "",
    "text": "From my analysis, I was able to get a better understanding of how fatigue affects physical metrics measured by Catapult devices. In my analysis of maximum velocity on the player level, I found that fatigue within a single match does not seem to affect whether players will hit a high maximum velocity. The average maximum velocity for the team is slightly higher in the first half and in the second half, which is expected. Intra-player differences in maximum velocity are very low between the first half and the second half. Furthermore, in my analysis of the MLS Next Tournament, I found that there was not a large impact of accumulated fatigue. The distribution of different sprinting speed distances was similar between the games (i.e. player’s did not seem to be sprinting less as the tournament progressed). That’s must mean that players are good at recovering and have good fitness. The matches that seemed the most affected by fatigue were the second match and the last match. As discussed above, that is expected because the second match was played the day after the first match. All of the other matches had at least one day’s rest in between. The last match presumably had lower values due to accumulated fatigue. In conclusion, fatigue definitely has an effect on player’s physical performance, but this needs to be analyzed further, and it varies on a case-by-case basis. High performing athletes seem to be very good at recovering quickly and minimizing the effects of fatigue.\n\nlibrary(dplyr)\n\n# Assuming your dataframe is called df and the columns are named 'Player.Name' and 'Maximum.Velocity'\nmax_speed_by_player &lt;- master_df %&gt;%\n  group_by(Player.Name) %&gt;%\n  summarise(Max_Speed = max(Maximum.Velocity, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\n# Assuming 'Identifier' in name_mapping matches 'Player.Name' in max_speed_by_player\nmax_speed_with_names &lt;- max_speed_by_player %&gt;%\n  left_join(name_mapping, by = c(\"Player.Name\" = \"Identifier\")) %&gt;%\n  select(Original_Name, Max_Speed)\n\n# View the results\nmax_speed_with_names\n\n# A tibble: 35 × 2\n   Original_Name      Max_Speed\n   &lt;chr&gt;                  &lt;dbl&gt;\n 1 Gabriel Arnold          17.9\n 2 Gustavo Gonzalez        18.7\n 3 Ryker Joutz             19.2\n 4 Allan Legaspi           20.6\n 5 Marcus Lightbourne      19.2\n 6 Julian Placias          20.7\n 7 Paulo Rudisill          19.5\n 8 Nico Schelotto          18.6\n 9 Harbor Miller           19.4\n10 Nathan Nava             17.7\n# ℹ 25 more rows\n\nlibrary(readxl)\n# Replace 'path_to_your_excel_file.xlsx' with the actual path to your Excel file\nplayer_data &lt;- read_excel(\"/Users/sylwialipior/Downloads/pm566-01-lab/Academy Data.xlsx\")\n\n# Create a new 'Original_Name' column by concatenating 'First_Name' and 'Last_Name'\nplayer_data &lt;- player_data %&gt;%\n  mutate(Original_Name = paste(First_Name, Last_Name))\n\n\n# Join the player data with max speed data\n# Make sure the key column names match those in your actual dataframes\ncombined_data &lt;- player_data %&gt;%\n  left_join(max_speed_with_names, by = 'Original_Name')\n\nlibrary(writexl)\n# Replace 'path_to_new_excel_file.xlsx' with the desired path for the new Excel file\nwrite_xlsx(combined_data, '/Users/sylwialipior/Downloads/pm566-01-lab/Academy Data_updated.xlsx')\n\n# Continuing from the previous combined_data dataframe\ncombined_data &lt;- combined_data %&gt;%\n  mutate(\n    Height_m = Height / 100, # Convert height from centimeters to meters\n    Weight_kg = Weight * 0.453592, # Convert weight from pounds to kilograms\n    BMI = Weight_kg / (Height_m^2) # Calculate BMI\n  )\n\n# View the first few rows to confirm the BMI column has been added\nhead(combined_data)\n\n# A tibble: 6 × 22\n  Date                Last_Name   First_Name Birth_Year Birth_Month Gender Team \n  &lt;dttm&gt;              &lt;chr&gt;       &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;\n1 2022-08-01 00:00:00 Dalgado     Riley            2006 August      M      U17  \n2 2022-08-01 00:00:00 Garcia      Emiliano         2006 January     M      U17  \n3 2022-08-01 00:00:00 Legaspi     Allan            2006 January     M      U17  \n4 2022-08-01 00:00:00 Placias     Julian           2006 April       M      U17  \n5 2022-08-01 00:00:00 Dunbar      Adam             2007 February    M      U17  \n6 2022-08-01 00:00:00 Lightbourne Marcus           2006 July        M      U17  \n# ℹ 15 more variables: Height &lt;dbl&gt;, Weight &lt;dbl&gt;, Body_Fat &lt;lgl&gt;, Yo_Yo &lt;dbl&gt;,\n#   ten_meter &lt;dbl&gt;, `20m` &lt;dbl&gt;, thirty_meter &lt;dbl&gt;, five_ten_five_L &lt;dbl&gt;,\n#   five_ten_five_R &lt;dbl&gt;, CMJ &lt;chr&gt;, Original_Name &lt;chr&gt;, Max_Speed &lt;dbl&gt;,\n#   Height_m &lt;dbl&gt;, Weight_kg &lt;dbl&gt;, BMI &lt;dbl&gt;\n\nlibrary(dplyr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\ncombined_data &lt;- combined_data %&gt;%\n  mutate(\n    # Convert 'Birth_Month' to a numeric value\n    Birth_Month_Num = match(Birth_Month, month.name),  # Assumes 'Birth_Month' is a three-letter abbreviation\n    Birthdate = make_date(Birth_Year, Birth_Month_Num, 1),\n    # Make sure 'Date' is a Date object; use the appropriate lubridate function if the format is different\n    Test_Date = as.Date(Date),  # Replace with mdy(Date), dmy(Date), etc., as appropriate\n    Age_at_Testing = as.numeric(difftime(Test_Date, Birthdate, units = \"weeks\")) / 52.25\n  )\n\n# View the first few rows to confirm the Age_at_Testing column has been added\nhead(combined_data)\n\n# A tibble: 6 × 26\n  Date                Last_Name   First_Name Birth_Year Birth_Month Gender Team \n  &lt;dttm&gt;              &lt;chr&gt;       &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;\n1 2022-08-01 00:00:00 Dalgado     Riley            2006 August      M      U17  \n2 2022-08-01 00:00:00 Garcia      Emiliano         2006 January     M      U17  \n3 2022-08-01 00:00:00 Legaspi     Allan            2006 January     M      U17  \n4 2022-08-01 00:00:00 Placias     Julian           2006 April       M      U17  \n5 2022-08-01 00:00:00 Dunbar      Adam             2007 February    M      U17  \n6 2022-08-01 00:00:00 Lightbourne Marcus           2006 July        M      U17  \n# ℹ 19 more variables: Height &lt;dbl&gt;, Weight &lt;dbl&gt;, Body_Fat &lt;lgl&gt;, Yo_Yo &lt;dbl&gt;,\n#   ten_meter &lt;dbl&gt;, `20m` &lt;dbl&gt;, thirty_meter &lt;dbl&gt;, five_ten_five_L &lt;dbl&gt;,\n#   five_ten_five_R &lt;dbl&gt;, CMJ &lt;chr&gt;, Original_Name &lt;chr&gt;, Max_Speed &lt;dbl&gt;,\n#   Height_m &lt;dbl&gt;, Weight_kg &lt;dbl&gt;, BMI &lt;dbl&gt;, Birth_Month_Num &lt;int&gt;,\n#   Birthdate &lt;date&gt;, Test_Date &lt;date&gt;, Age_at_Testing &lt;dbl&gt;\n\n\nLinear Regression\n\n# Let's assume your combined data with max speed, BMI, and age is named 'combined_data'\nmodel &lt;- lm(Max_Speed ~ Age_at_Testing + Height_m + Weight_kg + thirty_meter + ten_meter, data = combined_data)\nsummary(model)\n\n\nCall:\nlm(formula = Max_Speed ~ Age_at_Testing + Height_m + Weight_kg + \n    thirty_meter + ten_meter, data = combined_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.9410 -0.4834 -0.1384  0.4963  1.0577 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    64.08743   11.33309   5.655 1.88e-05 ***\nAge_at_Testing -0.34688    0.32666  -1.062    0.302    \nHeight_m       -1.65461    3.85506  -0.429    0.673    \nWeight_kg      -0.02074    0.03461  -0.599    0.556    \nthirty_meter   -8.17774    1.35102  -6.053 8.03e-06 ***\nten_meter      -0.16515    0.89072  -0.185    0.855    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6928 on 19 degrees of freedom\n  (140 observations deleted due to missingness)\nMultiple R-squared:  0.7461,    Adjusted R-squared:  0.6793 \nF-statistic: 11.17 on 5 and 19 DF,  p-value: 3.963e-05\n\nlibrary(caret)\n\nLoading required package: lattice\n\nlibrary(dplyr)\n\n# Filter out rows with NA in the thirty_meter column\ncombined_data_filtered &lt;- combined_data %&gt;% \n  filter(!is.na(thirty_meter) & !is.na(Max_Speed) & !is.na(ten_meter))\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Split data into training (75%) and test sets (25%)\ntrainIndex &lt;- createDataPartition(combined_data_filtered$Max_Speed, p = 0.8, list = FALSE, times = 1)\ntrainData &lt;- combined_data_filtered[trainIndex, ]\ntestData &lt;- combined_data_filtered[-trainIndex, ]\n\n# Fit the linear model on the training set\nmodel &lt;- lm(Max_Speed ~ Age_at_Testing + Height_m + Weight_kg + thirty_meter + ten_meter, data = trainData)\n\n# Summarize the model\nsummary(model)\n\n\nCall:\nlm(formula = Max_Speed ~ Age_at_Testing + Height_m + Weight_kg + \n    thirty_meter + ten_meter, data = trainData)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0378 -0.3590 -0.1233  0.5099  1.0563 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    68.699448  14.266118   4.816 0.000227 ***\nAge_at_Testing -0.412015   0.465008  -0.886 0.389581    \nHeight_m       -3.946296   4.228569  -0.933 0.365473    \nWeight_kg      -0.006261   0.038711  -0.162 0.873675    \nthirty_meter   -8.205729   1.545447  -5.310 8.74e-05 ***\nten_meter      -0.397217   0.944680  -0.420 0.680098    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7118 on 15 degrees of freedom\nMultiple R-squared:  0.7681,    Adjusted R-squared:  0.6907 \nF-statistic: 9.934 on 5 and 15 DF,  p-value: 0.00024\n\n# Predict on the test set\npredictions &lt;- predict(model, newdata = testData)\n\n# Calculate performance metrics, such as Mean Squared Error (MSE)\nmse &lt;- mean((testData$Max_Speed - predictions)^2)\nprint(paste(\"Mean Squared Error: \", mse))\n\n[1] \"Mean Squared Error:  0.446101767664014\"\n\n# Optionally, compare actual max speeds vs predicted max speeds\ncomparison &lt;- data.frame(Actual = testData$Max_Speed, Predicted = predictions)\nprint(comparison)\n\n    Actual Predicted\n1 20.12038  19.57192\n2 17.85323  18.80160\n3 18.18696  18.67113\n4 19.08000  18.48858\n\nlibrary(car)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n# Fit the linear model without the 'ten_meter' variable\nmodel_without_ten &lt;- lm(Max_Speed ~ Age_at_Testing + Height_m + Weight_kg + thirty_meter, data = trainData)\n\n# Calculate VIF for the model\nvif_results &lt;- vif(model_without_ten)\nprint(vif_results)\n\nAge_at_Testing       Height_m      Weight_kg   thirty_meter \n      2.625076       5.258976       5.661624       2.201260 \n\n# Alternatively, to get a nicely formatted output\nvif_df &lt;- data.frame(Variable = names(vif_results), VIF = vif_results)\nprint(vif_df)\n\n                     Variable      VIF\nAge_at_Testing Age_at_Testing 2.625076\nHeight_m             Height_m 5.258976\nWeight_kg           Weight_kg 5.661624\nthirty_meter     thirty_meter 2.201260"
  }
]